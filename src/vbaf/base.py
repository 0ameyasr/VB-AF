import random
import inspect
from typing import Callable, Generator, Any


def generate_fuzzy_payload(
    payload: str,
    vocabulary: list[str],
    seed: int | None = None,
    separator: str = "\u200b",
    join_on: str = "",
    rand_bounds: tuple[int] = (7, 21),
    position_bounds: tuple[float] = (0.5, 0.6),
    n_size: int = 100,
    save_file: bool = False,
    save_path: str = "",
    save_encoding: str = "utf-8",
) -> str:
    """Generates a single adversarial prompt using the VB-AF method.

    This function creates a fuzzy payload by embedding a harmful string (`payload`) within a
    larger block of chaotic token-based noise. The noise is generated by sampling from a provided
    token `vocabulary`.

    Args:
        payload (str): The core harmful or target string to embed.
        vocabulary (list[str]): A list of tokens (strings) to sample from to create the surrounding noise.
        seed (int): An integer seed for `random` choices.
        separator (str, optional): The character used to join individual tokens within a noise sequence. Defaults to the Zero-Width Space (ZWSP) '\\u200b'.
        join_on (str, optional): The character used to join the `n_size` token sequences together. Defaults to an empty string.
        rand_bounds (tuple[int], optional): A (min, max) tuple that defines the inclusive range for the number of tokens in each noise sequence. Defaults to (7,21).
        position_bounds (tuple[float], optional): A (min, max) float tuple that defines the inclusive closest-integer range from which a random position to insert the `payload` will be chosen. This is equivalent
            to setting a range `[int(min * n_size), int(max * n_size)]`. Defaults to (0.5, 0.6).
        n_size (int, optional): The total number of token sequences (noise + 1 payload sequence) in the final prompt. Defaults to 100.
        save_file (bool, optional): If True, saves the generated fuzzy payload to a text file. Defaults to False.
        save_path (str, optional): The path to the file where the payload will be saved if `save_file` is True.
        save_encoding (str, optional): The encoding to use when saving the file. Defaults to "utf-8".

    Returns:
        str: The fully constructed adversarial fuzzy payload.

    Raises:
        AssertionError:
        - If `rand_bounds` defines an invalid or out-of-bounds range relative to the vocabulary size, OR
        - If `position_bounds` defines an invalid range not included in [0,1]
        - If `n_size` <= 0
    """
    vocabulary_size = len(vocabulary)

    # Fix a seed if available
    if seed is not None:
        random.seed(seed)

    # Fuzzy payload must never be empty
    assert n_size > 0, f"n_size must be > 0, but got n_size={n_size}"

    # We must ensure that a token sequence can never be longer than the vocabulary itself
    assert (
        0 <= rand_bounds[0] < rand_bounds[1] <= vocabulary_size
    ), f"rand_bounds must define a valid inclusive range within [0, {vocabulary_size}], but got rand_bounds={rand_bounds}"

    # Similarly, we must also ensure that position bounds is within bounds
    assert (
        0 <= position_bounds[0] < position_bounds[1] <= 1
    ), f"position_bounds must define a valid inclusive range within [0,1], but got position_bounds={position_bounds}"

    argK_min: float
    argK_max: float
    argK_min, argK_max = position_bounds

    argK: int = random.randint(int(argK_min * n_size), int(argK_max * n_size))

    # Join all token sequences into a single fuzzy payload
    fuzzy_payload: str = join_on.join(
        [
            (
                (
                    # Join all tokens into a sequence using this separator
                    separator.join(
                        # All token sequences are of random length k
                        random.choices(vocabulary, k=random.randint(*rand_bounds))
                    )
                )
                if k != argK
                else f"{separator}{payload}{separator}"  # Payload is injected exactly at argK
            )
            for k in range(n_size)
        ]
    )

    # In case we want to save the fuzzy payload to a file with proper encoding
    if save_file:
        with open(save_path, "w", encoding=save_encoding) as fuzzy_buffer:
            fuzzy_buffer.write(fuzzy_payload)

    return fuzzy_payload


def fuzz(
    vocabulary: list[str],
    n_attempts: int = 100,
    **kwargs: Any,
) -> Callable:
    """A decorator to apply VB-AF fuzzing to an inference function.

    This decorator wraps an inference function that takes a string payload as its first argument (e.g. a function that calls an LLM's API). It
    transforms the decorated function into a fuzzing harness (generator) that, for each call, yields `n_attempts` of results by passing a newly
    generated fuzzy payload to the original inference function on each iteration.

    Args:
        vocabulary (list[str]): The vocabulary of tokens to use for fuzzing.
        n_attempts (int, optional): The number of fuzzing attempts to generate for each call to the decorated function. Defaults to 100.
        **kwargs: Arbitrary keyword arguments that will be passed directly to `generate_fuzzy_payload`. This allows for tuning parameters like
        `separator`, `rand_bounds`, `n_size`, etc.

    Returns:
        Callable: A decorator that transforms an inference function into a fuzzing harness generator.

    Raises:
        AssertionError:
        - If `n_attempts` <= 0
        - Any similar errors raised by `generate_fuzzy_payload`

    Example:
    ```python
        tokens = [str(i) for i in range(10)]

        @fuzz(vocabulary=tokens, n_attempts=3, rand_bounds=(2,5), n_size=10)
        def fuzzing_harness(prompt: str):
             # Ideally, this would call and LLM API
             return f"Mock response for: {prompt}"

        for result in fuzzing_harness("This is a mocked payload.")
             print(result)
    ```

    Note:
        Results generated by the fuzzing harness are returned as tuples in the form of `(fuzzy_payload, response)`.
        - `fuzzy_payload` is the fuzzy payload generated by VB-AF and that is sent to the LLM
        - `response` is the result returned from the original `fuzzing_harness` function. It may be the model's final response or multiple items depending on how the function handles the request.
        It is recommended that you unpack the response generated by the fuzzing harness.
    """
    assert n_attempts > 0, f"n_attempts must be > 0, but got n_attempts={n_attempts}"

    # A light warning for a large number of fuzzing attempts
    if n_attempts > 1000:
        print(
            f"WARNING: {n_attempts} fuzzing attempts (n_attempts) detected, which exceeds the recommended 1000 threshold. This may significantly impact performance, computation time and any API inference costs if involved."
        )

    # A decorator that wraps around the LLM inference function
    def decorator(inference: Callable) -> Callable:
        sig = inspect.signature(generate_fuzzy_payload)
        fuzzer_params = set(sig.parameters.keys())

        def wrapper(payload: str, *args, **wrapper_kwargs) -> Generator:
            for _ in range(n_attempts):
                fuzzer_kwargs = {
                    key: value for key, value in kwargs.items() if key in fuzzer_params
                }
                fuzzy_payload = generate_fuzzy_payload(
                    payload, vocabulary, **fuzzer_kwargs
                )

                inference_kwargs = {
                    key: value
                    for key, value in kwargs.items()
                    if key not in fuzzer_params
                }

                # This result can be the final response by the LLM, or a mixture of items, like involved Chain-of-Thought (CoT)
                result = inference(fuzzy_payload, *args, **inference_kwargs)

                yield (
                    fuzzy_payload,
                    result,
                )  # We often require fuzzy_payload for outcome analysis

        return wrapper

    return decorator
